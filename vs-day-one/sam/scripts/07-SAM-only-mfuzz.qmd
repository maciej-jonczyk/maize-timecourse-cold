---
title: "Mfuzz clustering of SAM data"
format: html
date: "2025-09-07"
bibliography: ../../../refs-stat-anal.bib
execute:
  fig-format: png
  fig.dpi: 300
---

The aim of this code is to fuzzy-cluster genes using Mfuzz package [@futschikNoiserobustSoftClustering2005; @kumarMfuzzSoftwarePackage2007]

Comparisons to day one (penultimate day of cold)


/media/mj/ANTIX-LIVE/2024_04_01.counts.PS
/media/mj/ANTIX-LIVE/expr-anal2powt

http://mfuzz.sysbiolab.eu/
https://support.bioconductor.org/p/9156659/ # uśrednianie reps i użycie vst
https://support.bioconductor.org/p/111294/ # info o cpm od developerów
https://support.bioconductor.org/p/9156710/ # garść info od Love



Built with R version `r getRversion()`

## R Preliminaries

Environment cleaning and set-up

```{r setup}
#| include: false
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir = "/home/mj/project1-stat/vs-day-one/sam/scripts")
```

```{r packages}
#| eval: false
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("Mfuzz")
BiocManager::install("marray")
BiocManager::install("limma")
```

```{r}
#| output: false

# Clean working directory
rm(list=ls())
```

## Create ExpressionSet from DESeq2 results

### Load significant genes

```{r load}
load("../rdata-saved/sigs_fc05.RDa")
```

### Extract significant genes' IDs

```{r sigs}

original_names <- grep("^[sa]", ls(), value = TRUE)

invisible(
  lapply(original_names, function(name) {
  obj <- get(name)
  
  result = rownames(obj)
  
  new_name <- paste0("ids.", name)
  assign(new_name, result, envir = .GlobalEnv)  # save new object
    }
  )
)

rm(list=ls(pattern = "^[sa]")) # remove original objects
rm(original_names)
```

### Join vectors and remove duplicates

```{r join}

vectors <- mget(ls(pattern = "^ids.*"))

# concatenate and remove duplicates
joined_ids <- unique(unlist(vectors))

rm(list=ls(pattern = "^ids.*")) # remove intermediate objects

```

### Load counts and normalize them using VST

```{r read data, cache=TRUE}
load("../../../input-data/rdata/counts_and_metadata.RDa")

# previously prepared range data
library("GenomicRanges")
load("../../../input-data/rdata/ranges.RDa")

# make variable for averaging
coldata$forAverage <- factor(paste0(coldata$line, ".", coldata$day, coldata$time))

# Check if files are in concert
all(rownames(coldata) %in% colnames(cts))
all(rownames(coldata) == colnames(cts))
```

### Change samples' order

```{r sort}
# sort colData
coldata.srt <- coldata[order(rownames(coldata)), ]

# sort counts columns
cts.srt <- cts[, rownames(coldata.srt)]

# Check if files are in concert
all(rownames(coldata.srt) %in% colnames(cts.srt))
all(rownames(coldata.srt) == colnames(cts.srt))

# remove original objects
rm(list=c("cts", "coldata"))
```

### Subset SAM data

Subsetting is done at the level of raw data (counts and coldata).
```{r subset SAM data}
# subset coldata to contain only sam data
coldata.sam=subset(coldata.srt, tissue=="sam")

# check
dim(coldata.sam)

# vector of sample names to keep - needed to select columns from count file
keep.sam=rownames(coldata.sam)

# check - only samples named "s..." should remain
keep.sam
length(keep.sam)

# subsetting counts
cts.sam=subset(cts.srt, select=keep.sam)

# check
dim(cts.sam)
colnames(cts.sam)

# Check if counts and coldata are in concert
all(rownames(coldata.sam) %in% colnames(cts.sam))
all(rownames(coldata.sam) == colnames(cts.sam))
```

### Create DESeq2 object

```{r dds, cache=TRUE}
#| output: false
#| message: false
library("DESeq2")
# create dataset, design included only for command completeness
dds = DESeqDataSetFromMatrix(countData=cts.sam, colData=coldata.sam, rowRanges=gzakresy, design= ~ line+time)

# check for missing values
any(is.na(counts(dds)))

# check
table(colData(dds)$tissue)
```

### Pre-filtering

```{r pre-filtering, cache=TRUE}
# at least 3 samples with a count of 10 or higher
keep <- rowSums(counts(dds) >= 10) >= 3
dds.f <- dds[keep,]

# check
dim(dds.f)

# what percent of genes remained?
100*(dim(dds.f)[1]/dim(dds)[1])
```

```{r normalize, cache=TRUE}
vsd = varianceStabilizingTransformation(dds.f, blind=TRUE)
```

```{r cleanup}
# objects to keep
keep <- c("vsd", "joined_ids")

# remove everything else
rm(list = setdiff(ls(), keep))
```

### Select counts for sigs

```{r counts}
# select sigs
vsd.sigs = vsd[rownames(vsd) %in% joined_ids, ]

# varMetadata - description of variables
metadata=data.frame(labelDescription=c("pooled sample", "letter", "tissue", "line", "hour of pooling", "sample number", "day", "replication", "condition", "id", "reads [million]", "batch [sequencing]", "million of reads binned", "grouping variable for averaging", "sizeFactor"), row.names=colnames(colData(vsd.sigs)))

# metadata
phenoData=new("AnnotatedDataFrame", data=as.data.frame(colData(vsd.sigs)), varMetadata=metadata)
phenoData

## check
# sampleNames(phenoData)
# pData(phenoData)
# varMetadata(phenoData)
# head(pData(phenoData))

# make ExpressionSet
vsd.eset <- ExpressionSet(assayData=assay(vsd.sigs), phenoData=phenoData)
```

### Averaging and standardizing

```{r avg and std}
library(limma)

# average reps
average = t(avereps(t(exprs(vsd.eset)), ID = vsd.eset$forAverage)) # output is a matrix

# check
dim(average)
dim(vsd.eset)

## make new phenoData
phenoDataAve = phenoData[!duplicated(vsd.eset$forAverage), ]
rownames(phenoDataAve)= phenoDataAve$forAverage

library(dplyr)

pdata_sorted <- pData(phenoDataAve) %>%
  arrange(line, day, time)

# i potem, jeśli chcesz przywrócić AnnotatedDataFrame:
pData(phenoDataAve) <- pdata_sorted

# sort counts columns
average.srt <- average[, rownames(pData(phenoDataAve))]

all(rownames(pData(phenoDataAve) ) %in% colnames(average.srt))
all(rownames(pData(phenoDataAve) ) == colnames(average.srt))

vsd.eset.ave=ExpressionSet(assayData=average.srt, phenoData=phenoDataAve)

# standardise
library(Mfuzz)
vsd.eset.ave.std=standardise(vsd.eset.ave)

# check
head(exprs(vsd.eset.ave.std))

```

### Standardising and averaging

```{r std and ave}
library(limma)

# standardise
library(Mfuzz)

vsd.eset.std=standardise(vsd.eset)

# average reps
average.std = t(avereps(t(exprs(vsd.eset.std)), ID = vsd.eset.std$forAverage)) # output is a matrix

# check
dim(average.std)
dim(vsd.eset.std)

## make new phenoData
phenoDataAve = phenoData[!duplicated(vsd.eset.std$forAverage), ]
rownames(phenoDataAve)= phenoDataAve$forAverage

library(dplyr)

pdata_sorted <- pData(phenoDataAve) %>%
  arrange(line, day, time)

# i potem, jeśli chcesz przywrócić AnnotatedDataFrame:
pData(phenoDataAve) <- pdata_sorted

# sort counts columns
average.std.srt <- average.std[, rownames(pData(phenoDataAve))]

all(rownames(pData(phenoDataAve) ) %in% colnames(average.std.srt))
all(rownames(pData(phenoDataAve) ) == colnames(average.std.srt))

vsd.eset.std.ave=ExpressionSet(assayData=average.std.srt, phenoData=phenoDataAve)
```

### Saving and cleanup

Correct order of aperations (standardisation, averaging) will be decided later

```{r cleanup2}
# objects to keep
keep <- c("vsd.eset.ave.std", "vsd.eset.std.ave")

# remove everything else
rm(list = setdiff(ls(), keep))

save(vsd.eset.std.ave, file="../rdata-saved/vsd.eset.std.ave.sam.RDa")
save(vsd.eset.ave.std, file="../rdata-saved/vsd.eset.ave.std.sam.RDa")
```

## Clustering, test for vsd.eset.ave.std

### Estimate fuzzification parameters

```{r estimate m}
# objects to keep
keep <- c("vsd.eset.ave.std")

# remove everything else
rm(list = setdiff(ls(), keep))

# fuzzification parameter
m1 <- mestimate(vsd.eset.ave.std)

m1
```

```{r estimate c}
# # using estimated m
# 
# cl1=mfuzz(vsd.eset.std, c=16, m=m1)
# 
# pdf("cl16_104R.pdf")
# #mfuzz.plot2(vsd.eset.std, cl=cl1, x11 = FALSE, single = 1, time.labels = colnames(vsd.eset.std), cex.axis = 0.6, las = 2)
# #mfuzz.plot2(vsd.eset.std, cl=cl1, x11 = FALSE, single = 1, time.labels = colnames(vsd.eset.std))
# mfuzz.plot2(vsd.eset.std, cl=cl1, mfrow=c(4,4), x11 = FALSE)
# dev.off()
```

### Estimate m using `partcoef`

```{r parameters}
## Deciding on cluster parameters ##
# m is already estimated
## TAKEN FROM partcoeff DESCRIPTION IN MANUAL
vsd.random=randomise(vsd.eset.ave.std)

tmpR=partcoef(vsd.random, crange=seq(7, 25, 1),mrange=seq(1.05, 1.25, 0.05))
# tmpR=partcoef(vsd.random, crange=seq(16, 40, 1), mrange=seq(1.05, 2, 0.05))
F <- tmpR[[1]];F.n <- tmpR[[2]];F.min <- tmpR[[3]]
F > 1.01 * F.min

# it seems that value given by mestimate is too low and minimum m = 1.1 should be used

library(Mfuzz)
# draw and save legend (uses modified function as this from package not work)
source("../../../colorbar.R")
pdf("colorbar.pdf", width=2, height=7)
colorBar()
dev.off()
```

```{r check random}
# RANODM

##############################
# Adjust parameters manually #
##############################

# c_val <- 4 ; m_val <- 1.05 # Non uniform partition (too low m value)
# c_val <- 8 ; m_val <- 1.05 # Non uniform partition (too low m value)
# c_val <- 16 ; m_val <- 1.05 # Non uniform partition (too low m value)
# c_val <- 4 ; m_val <- 1.15 # produces uniform partitioning
# c_val <- 8 ; m_val <- 1.15 # produces uniform partitioning
# c_val <- 16 ; m_val <- 1.15 # produces uniform partitioning

# MFuzz analysis using variables above
cl <- mfuzz(vsd.random, c = c_val, m = m_val)

# dynamic naming of objects
filename <- paste0("cl", c_val, "_", m_val, "R.pdf")

pdf(filename)
mfuzz.plot2(vsd.random, cl = cl, mfrow = c(4, 2), x11 = FALSE)
dev.off()

```

### Automatic check for given combinations of c and m. Two methods.

```{r c auto}
library(Mfuzz)
load("../rdata-saved/vsd.eset.ave.std.sam.RDa")


# m values for testing
m_vals <- seq(1.25, 1.45, by = 0.05)

# list with results
c_results <- list()

for (m_val in m_vals) {
  
  # file name eg. "c_m1.15.pdf"
  filename <- paste0("c_m", m_val, ".pdf")
  
  pdf(filename)
  c_res <- cselection(vsd.eset.ave.std, m = m_val, crange=seq(15, 35, 1), repeats=10, visu=TRUE)
  dev.off()
  
  # save result to list
  key <- paste0("c", m_val)
  c_results[[key]] <- c_res
}

c = 23, 25 ? with m = 1.4
```


```{r dmin auto}
library(Mfuzz)

# m values for testing
# m_vals <- seq(1.25, 1.4, by = 0.05)

# Some complimentary try
m_vals <- seq(1.10, 1.2, by = 0.05)

# list with results
dmin_results <- list()

for (m_val in m_vals) {
  
  # file name eg. "Dmin_m1.15.pdf"
  filename <- paste0("Dmin_m", m_val, ".pdf")
  
  pdf(filename)
  dmin_res <- Dmin(vsd.eset.ave.std, 
                   m = m_val, 
                   crange = seq(7, 40, 1), 
                   repeats = 10, 
                   visu = TRUE)
  dev.off()
  
  # save result to list
  key <- paste0("m", m_val)
  dmin_results[[key]] <- dmin_res
}

# c = 8 ? for m =1.3 - 1.4, with optimum 1.35

# c = 14 for m =1.3, from Dmin

# Other options
# c = 20, m = 1.1
# c = 23, m =1.15
# c = 10, m = 1.2
```

```{r check real}
#REAL

library(Mfuzz)

# REMEMBER TO UN/COMMENT APPROPRIATE LINES BELOW

# c_vals <- c(23, 25) # c = 23, 25 ? with m = 1.4 from cselection
# m_vals <- c(1.4)  # c = 23, 25 ? with m = 1.4 from cselection

# c_vals = 8 # c = 8 ? for m =1.3 - 1.4, with optimum 1.35 from Dmin
# m_vals = seq(1.3, 1.4, by=0.05) # c = 8 ? for m =1.3 - 1.4, with optimum 1.35 from Dmin

# c_vals = 14 # c = 14 for m =1.3, from Dmin
# m_vals = seq(1.25, 1.4, by=0.05) # c = 14 for m =1.3, from Dmin

c_vals = 19 # from cselection
m_vals = 1.4 # from cselection

source("mfuzz.plot2_separate_lines.R") # modified plotting function, tailored to seprarate lines

# lista wyników
results <- list()

# loop for given combinations of c and m
for (c_val in c_vals) {
  for (m_val in m_vals) {
    
    set.seed(1) # for reproducibility
    
    # clustering
    cl <- mfuzz(vsd.eset.ave.std, c = c_val, m = m_val)
    
    # save results to list
    key <- paste0("c", c_val, "_m", m_val)
    results[[key]] <- cl
    
    # dynamic naming of file
    filename <- paste0("cl", c_val, "_", m_val, ".pdf")

    # save plot
    pdf(filename)
    mfuzz.plot2mod(vsd.eset.ave.std, cl = cl, mfrow = c(2,1), x11 = FALSE, centre=TRUE, centre.col="black", centre.lwd=2,
                time.labels = colnames(vsd.eset.ave.std),  cex.axis = 0.6, las = 2)
    dev.off()
    
    # Plot for genes witn membership >= 0.7
    # dynamic naming of file
    filename07 <- paste0("cl", c_val, "_", m_val, "minmem07.pdf")

    # save plot
    pdf(filename07)
    mfuzz.plot2mod(vsd.eset.ave.std, cl = cl, min.mem = 0.7, mfrow = c(2,1), x11 = FALSE, centre=TRUE, 
                   centre.col="black", centre.lwd=2, time.labels = colnames(vsd.eset.ave.std),  cex.axis = 0.6, las = 2)
    dev.off()
  }
}

# results_csel = results # from cselection

results_dmin = results # from Dmin

```

```{r overlaps}
# list of clustering results:
# results[["c14_m1.20"]] <- cl14_120

# list to save overlap results
overlaps <- list()

# REMEMBER to change results_... object

for (key in names(results_dmin)) {
  # for (key in names(results_csel)) {
    
  # cl <- results_csel[[key]]
  cl <- results_dmin[[key]]
    
  # compute overlap
  ov <- overlap(cl)
  overlaps[[key]] <- ov
  
  # PDF file name eg. "c14_m1.20_overlap.pdf"
  filename <- paste0(key, "_overlap.pdf")
  
  pdf(filename)
  overlap.plot(cl, over = ov, thres = 0.05)
  dev.off()
}
```

## Export results for chosen parameters

```{r selected}

# Replace all occurences of cluster name as needed

c14_m1.3 <- results_dmin[["c14_m1.3"]]


genes_in_clusters <- lapply(1:ncol(c14_m1.3$membership), function(i) {
  geny <- rownames(c14_m1.3$membership)[c14_m1.3$membership[, i] >= 0.7]
  return(geny)
})

# Name clusters
names(genes_in_clusters) <- paste("Klaster", 1:ncol(c14_m1.3$membership))

save(c14_m1.3, genes_in_clusters, file="../rdata-saved/mfuzz_c14_m1.3_sam.RDa")
# save(results_dmin, results_csel, file="../rdata-saved/mfuzz_different_options_sam.RDa")
save(results_dmin, file="../rdata-saved/mfuzz_different_options_sam2.RDa")

```

## References